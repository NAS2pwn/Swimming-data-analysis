{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingestion des données en base de données\n",
    "\n",
    "Pour résumer, l'objectif du projet est de s'entraîner en SQL et en Python pour se maintenir à jour en SQL (notamment les CTEs, les windows functions et les RANKS) et en Python (dataframes, SQLAlchemy, Pydantic, FastAPI, tests unitaires, Mock si pertinent, et si pertinent un peu d'intégration de modèles de machine learning).\n",
    "\n",
    "La première chose dans ce notebook ça va être de préparer les données et de les importer dans une DB PostgreSQL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer les données\n",
    "\n",
    "D'abord on regarde les données pour comprendre la structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Location', 'Year', 'Distance (in meters)', 'Stroke', 'Relay?',\n",
      "       'Gender', 'Team', 'Athlete', 'Results', 'Rank'],\n",
      "      dtype='object')\n",
      "  Location  Year Distance (in meters)      Stroke  Relay? Gender Team  \\\n",
      "0    Tokyo  2020                 100m  Backstroke       0    Men  ROC   \n",
      "1    Tokyo  2020                 100m  Backstroke       0    Men  ROC   \n",
      "2    Tokyo  2020                 100m  Backstroke       0    Men  USA   \n",
      "3    Tokyo  2020                 100m  Backstroke       0    Men  ITA   \n",
      "4    Tokyo  2020                 100m  Backstroke       0    Men  CHN   \n",
      "\n",
      "              Athlete Results  Rank  \n",
      "0        Evgeny Rylov   51.98     1  \n",
      "1  Kliment Kolesnikov      52     2  \n",
      "2         Ryan Murphy   52.19     3  \n",
      "3       Thomas Ceccon    52.3     4  \n",
      "4            Jiayu Xu   52.51     4  \n",
      "Distances distinctes: ['100m' '1500m' '200m' '400m' '50m' '800m' '4x100' '4x200']\n",
      "Nombre de résultats distincts: 3636\n",
      "\n",
      "100 résultats distincts aléatoires:\n",
      "00:10:19.400000\n",
      "00:04:59.800000\n",
      "00:02:13.740000\n",
      "00:09:36.200000\n",
      "00:02:15.380000\n",
      "00:03:37.460000\n",
      "00:01:01.600000\n",
      "1:57.31\n",
      "00:01:58.000000\n",
      "00:04:26.360000\n",
      "00:04:35.800000\n",
      "55.580\n",
      "00:03:58.230000\n",
      "00:02:10.700000\n",
      "00:01:18.800000\n",
      "00:02:12.340000\n",
      "00:07:24.030000\n",
      "00:01:45.490000\n",
      "00:08:03.690000\n",
      "00:05:35.700000\n",
      "00:01:10.000000\n",
      "00:07:25.630000\n",
      "00:01:05.780000\n",
      "00:03:31.580000\n",
      "14:39.65\n",
      "00:03:44.910000\n",
      "00:03:21.070000\n",
      "00:08:31.970000\n",
      "00:03:06.400000\n",
      "00:04:01.490000\n",
      "00:02:36.220000\n",
      "00:02:51.900000\n",
      "00:02:10.300000\n",
      "00:03:46.900000\n",
      "00:01:58.890000\n",
      "00:02:31.450000\n",
      "00:07:26.720000\n",
      "00:02:25.900000\n",
      "00:02:13.000000\n",
      "00:03:43.100000\n",
      "00:01:08.400000\n",
      "00:03:30.650000\n",
      "00:04:48.100000\n",
      "00:03:11.480000\n",
      "00:03:20.160000\n",
      "00:03:57.930000\n",
      "53.750\n",
      "00:04:27.810000\n",
      "00:03:40.910000\n",
      "00:03:40.540000\n",
      "00:07:52.300000\n",
      "51.810\n",
      "00:07:13.660000\n",
      "00:04:44.100000\n",
      "00:02:06.660000\n",
      "00:01:07.440000\n",
      "00:02:00.590000\n",
      "00:02:10.680000\n",
      "00:04:42.200000\n",
      "00:02:51.300000\n",
      "00:02:08.510000\n",
      "00:02:24.060000\n",
      "52.000\n",
      "00:08:28.900000\n",
      "00:01:04.260000\n",
      "00:01:15.730000\n",
      "00:05:43.400000\n",
      "00:02:13.970000\n",
      "00:02:11.930000\n",
      "00:02:03.150000\n",
      "00:02:12.600000\n",
      "00:02:09.250000\n",
      "23:04.0est\n",
      "00:04:29.230000\n",
      "59.690\n",
      "24.510\n",
      "00:02:18.860000\n",
      "00:01:58.870000\n",
      "21.590\n",
      "00:04:47.510000\n",
      "00:08:23.860000\n",
      "00:02:08.150000\n",
      "00:04:06.240000\n",
      "00:03:35.910000\n",
      "00:16:36.030000\n",
      "00:03:48.590000\n",
      "3:56.69\n",
      "00:09:18.200000\n",
      "58.000\n",
      "00:04:15.710000\n",
      "00:03:29.240000\n",
      "00:01:01.390000\n",
      "00:02:12.900000\n",
      "00:02:14.600000\n",
      "58.200\n",
      "00:08:27.750000\n",
      "56.260\n",
      "00:04:41.000000\n",
      "00:02:30.380000\n",
      "00:02:25.720000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = \"Olympic_Swimming_Results_1912to2020\"\n",
    "\n",
    "# Lire le fichier CSV et afficher les colonnes\n",
    "df = pd.read_csv(dataset_path + \".csv\")\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "\n",
    "distinct_distances = df['Distance (in meters)'].unique()  # Assurez-vous que le nom de la colonne est correct\n",
    "print(\"Distances distinctes:\", distinct_distances)\n",
    "\n",
    "distinct_results = df['Results'].unique()\n",
    "print(\"Nombre de résultats distincts:\", len(distinct_results))\n",
    "\n",
    "# Sélectionner aléatoirement 100 résultats distincts (ou moins s'il y en a moins de 100)\n",
    "sample_size = min(100, len(distinct_results))\n",
    "random_sample = np.random.choice(distinct_results, size=sample_size, replace=False)\n",
    "\n",
    "print(f\"\\n{sample_size} résultats distincts aléatoires:\")\n",
    "for result in random_sample:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On renomme les colonnes pour les rendre plus faciles à utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  location  year distance      stroke  is_relay gender team  \\\n",
      "0    Tokyo  2020     100m  Backstroke         0    Men  ROC   \n",
      "1    Tokyo  2020     100m  Backstroke         0    Men  ROC   \n",
      "2    Tokyo  2020     100m  Backstroke         0    Men  USA   \n",
      "3    Tokyo  2020     100m  Backstroke         0    Men  ITA   \n",
      "4    Tokyo  2020     100m  Backstroke         0    Men  CHN   \n",
      "\n",
      "              athlete results  rank  \n",
      "0        Evgeny Rylov   51.98     1  \n",
      "1  Kliment Kolesnikov      52     2  \n",
      "2         Ryan Murphy   52.19     3  \n",
      "3       Thomas Ceccon    52.3     4  \n",
      "4            Jiayu Xu   52.51     4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Renommer les colonnes\n",
    "df = df.rename(columns={\n",
    "    'Location': 'location',\n",
    "    'Year': 'year',\n",
    "    'Distance (in meters)': 'distance',\n",
    "    'Stroke': 'stroke',\n",
    "    'Relay?': 'is_relay',\n",
    "    'Gender': 'gender',\n",
    "    'Team': 'team',\n",
    "    'Athlete': 'athlete',\n",
    "    'Results': 'results',\n",
    "    'Rank': 'rank'\n",
    "})\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On convertit la colonne is_relay en booléen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  location  year distance      stroke  is_relay gender team  \\\n",
      "0    Tokyo  2020     100m  Backstroke     False    Men  ROC   \n",
      "1    Tokyo  2020     100m  Backstroke     False    Men  ROC   \n",
      "2    Tokyo  2020     100m  Backstroke     False    Men  USA   \n",
      "3    Tokyo  2020     100m  Backstroke     False    Men  ITA   \n",
      "4    Tokyo  2020     100m  Backstroke     False    Men  CHN   \n",
      "\n",
      "              athlete results  rank  \n",
      "0        Evgeny Rylov   51.98     1  \n",
      "1  Kliment Kolesnikov      52     2  \n",
      "2         Ryan Murphy   52.19     3  \n",
      "3       Thomas Ceccon    52.3     4  \n",
      "4            Jiayu Xu   52.51     4  \n"
     ]
    }
   ],
   "source": [
    "# Convertir 'is_relay' en booléen\n",
    "df['is_relay'] = df['is_relay'].map(lambda x: True if x == 1 else False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait la distance et le nombre de relais. On aura besoin de la distance en entier pour analyser correctement les données. Dans le CSV de base c'est un string au format [0-9]+m si c'est pas du relais (e.g 100m), et [0-9]+x[0-9]+m si c'est un relais (e.g 4x100m)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 100\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "4 200\n",
      "  location  year  distance      stroke  is_relay gender team  \\\n",
      "0    Tokyo  2020       100  Backstroke     False    Men  ROC   \n",
      "1    Tokyo  2020       100  Backstroke     False    Men  ROC   \n",
      "2    Tokyo  2020       100  Backstroke     False    Men  USA   \n",
      "3    Tokyo  2020       100  Backstroke     False    Men  ITA   \n",
      "4    Tokyo  2020       100  Backstroke     False    Men  CHN   \n",
      "\n",
      "              athlete results  rank  nb_relay  \n",
      "0        Evgeny Rylov   51.98     1       NaN  \n",
      "1  Kliment Kolesnikov      52     2       NaN  \n",
      "2         Ryan Murphy   52.19     3       NaN  \n",
      "3       Thomas Ceccon    52.3     4       NaN  \n",
      "4            Jiayu Xu   52.51     4       NaN  \n",
      "    location  year  distance     stroke  is_relay gender team  \\\n",
      "408      Rio  2016       100  Freestyle      True    Men  USA   \n",
      "409      Rio  2016       100  Freestyle      True    Men  FRA   \n",
      "410      Rio  2016       100  Freestyle      True    Men  AUS   \n",
      "411      Rio  2016       100  Freestyle      True    Men  RUS   \n",
      "412      Rio  2016       100  Freestyle      True    Men  BRA   \n",
      "\n",
      "                                               athlete          results  rank  \\\n",
      "408  Ryan Held, Anthony Ervin, Michael Phelps, Jame...  00:03:09.920000     1   \n",
      "409  William Meynard, Jeremy Stravius, Fabien Gilot...  00:03:10.530000     2   \n",
      "410  Cameron Mcevoy, Kyle Chalmers, Matthew Abood, ...  00:03:11.370000     3   \n",
      "411  Aleksandr Popkov, Andrey Grechin, Danila Izoto...  00:03:11.640000     4   \n",
      "412  Joao De Lucca, Marcelo Chierighini, Gabriel Da...  00:03:13.210000     4   \n",
      "\n",
      "     nb_relay  \n",
      "408       4.0  \n",
      "409       4.0  \n",
      "410       4.0  \n",
      "411       4.0  \n",
      "412       4.0  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Fonction pour extraire la distance et le nombre de relais\n",
    "def extract_distance_and_relay(distance_str):\n",
    "    if 'x' in distance_str:\n",
    "        nb_relay_str, distance_str = re.findall(r'\\d+', distance_str)\n",
    "        print(nb_relay_str, distance_str)\n",
    "        return int(distance_str), int(nb_relay_str)\n",
    "    else:\n",
    "        distance = int(re.findall(r'\\d+', distance_str)[0])\n",
    "        return distance, None\n",
    "\n",
    "# Appliquer la transformation à la colonne 'distance'\n",
    "df['distance'], df['nb_relay'] = zip(*df['distance'].apply(extract_distance_and_relay))\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df_relay_true = df[df['is_relay'] == True]\n",
    "print(df_relay_true.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, faut harmoniser les formats de temps. Dans le CSV de base, les temps sont dans des formats divers, parfois avec des minutes et des secondes, parfois avec des heures, parfois avec des décimales. On va tout convertir en secondes, sous forme de float avec une précision à la microseconde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  location  year  distance      stroke  is_relay gender team  \\\n",
      "0    Tokyo  2020       100  Backstroke     False    Men  ROC   \n",
      "1    Tokyo  2020       100  Backstroke     False    Men  ROC   \n",
      "2    Tokyo  2020       100  Backstroke     False    Men  USA   \n",
      "3    Tokyo  2020       100  Backstroke     False    Men  ITA   \n",
      "4    Tokyo  2020       100  Backstroke     False    Men  CHN   \n",
      "\n",
      "              athlete  results  rank  nb_relay quit_reason  \n",
      "0        Evgeny Rylov    51.98     1       NaN        None  \n",
      "1  Kliment Kolesnikov    52.00     2       NaN        None  \n",
      "2         Ryan Murphy    52.19     3       NaN        None  \n",
      "3       Thomas Ceccon    52.30     4       NaN        None  \n",
      "4            Jiayu Xu    52.51     4       NaN        None  \n",
      "\n",
      "Colonnes du DataFrame: Index(['location', 'year', 'distance', 'stroke', 'is_relay', 'gender', 'team',\n",
      "       'athlete', 'results', 'rank', 'nb_relay', 'quit_reason'],\n",
      "      dtype='object')\n",
      "\n",
      "50 valeurs aléatoires du DataFrame :\n",
      "       location  year  distance             stroke  is_relay gender team  \\\n",
      "3982     Berlin  1936       400          Freestyle     False  Women  DEN   \n",
      "1995  Barcelona  1992        50          Freestyle     False  Women  FRA   \n",
      "3568       Rome  1960       200       Breaststroke     False  Women  GBR   \n",
      "544      London  2012      1500          Freestyle     False    Men  CHN   \n",
      "2340    Angeles  1984       200         Backstroke     False  Women  USA   \n",
      "1375     Sydney  2000       200          Freestyle     False    Men  AUS   \n",
      "299         Rio  2016       200         Backstroke     False    Men  CHN   \n",
      "1012     Athens  2004       100       Breaststroke     False    Men  KAZ   \n",
      "1785  Barcelona  1992       100       Breaststroke     False  Women  USA   \n",
      "3975     Berlin  1936       400          Freestyle     False    Men  AUT   \n",
      "1028     Athens  2004       100          Butterfly     False    Men  RUS   \n",
      "4275    Antwerp  1920       400       Breaststroke     False    Men  SWE   \n",
      "1395     Sydney  2000       200  Individual medley     False  Women  CAN   \n",
      "3080     Munich  1972       400  Individual medley     False  Women  AUS   \n",
      "3573       Rome  1960       200       Breaststroke     False  Women  USA   \n",
      "90        Tokyo  2020       400  Individual medley     False    Men  AUS   \n",
      "1535    Atlanta  1996       100       Breaststroke     False  Women  BEL   \n",
      "4347  Stockholm  1912       400          Freestyle     False    Men  HUN   \n",
      "3637  Melbourne  1956       100         Backstroke     False    Men  GBR   \n",
      "3423      Tokyo  1964       200       Breaststroke     False    Men  URS   \n",
      "2694     Moscow  1980       800          Freestyle     False  Women  GDR   \n",
      "3977     Berlin  1936       400          Freestyle     False  Women  DEN   \n",
      "3792   Helsinki  1952       400          Freestyle     False    Men  FRA   \n",
      "1141     Athens  2004       200  Individual medley     False  Women  AUS   \n",
      "719      London  2012        50          Freestyle     False    Men  AUS   \n",
      "566      London  2012       200         Backstroke     False  Women  FRA   \n",
      "2354    Angeles  1984       200       Breaststroke     False  Women  BEL   \n",
      "1239     Athens  2004        50          Freestyle     False  Women  BRA   \n",
      "364         Rio  2016       200  Individual medley     False    Men  USA   \n",
      "2860   Montreal  1976       400  Individual medley     False  Women  GDR   \n",
      "1941  Barcelona  1992       400  Individual medley     False  Women  GER   \n",
      "4337  Stockholm  1912       400       Breaststroke     False    Men  GBR   \n",
      "4321  Stockholm  1912      1500          Freestyle     False    Men  ANZ   \n",
      "94        Tokyo  2020       400  Individual medley     False    Men  NZL   \n",
      "3369      Tokyo  1964       100         Backstroke     False  Women  FRA   \n",
      "3144       City  1968       100         Backstroke     False  Women  USA   \n",
      "1089     Athens  2004       200       Breaststroke     False  Women  AUS   \n",
      "2369    Angeles  1984       200          Butterfly     False  Women  AUS   \n",
      "813     Beijing  2008       200         Backstroke     False    Men  AUS   \n",
      "1125     Athens  2004       200          Freestyle     False  Women  USA   \n",
      "17        Tokyo  2020       100          Butterfly     False    Men  HUN   \n",
      "662      London  2012       400  Individual medley     False  Women  USA   \n",
      "1717    Atlanta  1996       100             Medley      True  Women  GER   \n",
      "678      London  2012       100          Freestyle      True  Women  JPN   \n",
      "2712   Montreal  1976       100       Breaststroke     False    Men  USA   \n",
      "671      London  2012       100          Freestyle      True    Men  BEL   \n",
      "703      London  2012       200          Freestyle      True    Men  HUN   \n",
      "3834     London  1948       100         Backstroke     False  Women  AUS   \n",
      "1913  Barcelona  1992       400          Freestyle     False    Men  AUS   \n",
      "4149  Amsterdam  1928       100          Freestyle      True  Women  GER   \n",
      "\n",
      "                                                athlete  results  rank  \\\n",
      "3982                          Grethe Ortved Frederiksen   345.00     4   \n",
      "1995                                Catherine Plewinski    25.36     4   \n",
      "3568                                   Anita Lonsbrough   169.50     1   \n",
      "544                                            Yang Sun   871.02     1   \n",
      "2340                                  Torri Leigh Trees   135.73     4   \n",
      "1375                                      Grant Hackett   109.46     4   \n",
      "299                                            Jiayu Xu   115.16     4   \n",
      "1012                                 Vladislav Polyakov    61.34     4   \n",
      "1785                                         Anita Nall    68.17     2   \n",
      "3975                                   Günther Zobernig      NaN     0   \n",
      "1028                                     Igor Marchenko    52.32     4   \n",
      "4275                                        Tor Henning   405.20     3   \n",
      "1395                             Marianne Luise Limpert   133.44     4   \n",
      "3080                                         Gail Neall   302.97     1   \n",
      "3573                                 Anna Kindel Warner   175.40     4   \n",
      "90                                        Brendon Smith   250.38     3   \n",
      "1535                                     Brigitte Becue    69.79     4   \n",
      "4347                                    Béla Las Torres   342.00     4   \n",
      "3637                                       Graham Sykes    65.60     4   \n",
      "3423                                  Vladimir Kosinsky   158.10     4   \n",
      "2694                                      Ines Geissler   525.28     4   \n",
      "3977                                Ragnild Tove Hveger   327.50     2   \n",
      "3792                                       Jean Boiteux   270.70     1   \n",
      "1141                                       Lara Carroll   133.74     4   \n",
      "719                                      Eamon Sullivan    21.98     4   \n",
      "566                                    Alexianne Castel   128.43     4   \n",
      "2354                                   Ingrid Lempereur   151.40     3   \n",
      "1239                                  Flavia Cazziolato    25.20     4   \n",
      "364                                         Ryan Lochte   117.47     4   \n",
      "2860                                       Sabine Kahle   293.50     4   \n",
      "1941                                     Daniela Hunger   287.57     4   \n",
      "4337                                     Percy Courtman   396.40     3   \n",
      "4321                                 Harold H. Hardwick  1395.40     3   \n",
      "94                                      Lewis Clareburt   251.22     4   \n",
      "3369                             Christine (Kiki) Caron    67.90     2   \n",
      "3144                                    Kaye Marie Hall    66.20     1   \n",
      "1089                                       Leisel Jones   143.60     2   \n",
      "2369                                     Karen Phillips   130.56     2   \n",
      "813                                     Hayden Stoeckel   116.39     4   \n",
      "1125                                       Dana Vollmer   118.98     4   \n",
      "17                                Kristof Kristof Milak    49.68     2   \n",
      "662                                    Caitlin Leverenz   275.49     4   \n",
      "1717  Antje Buschschulte, Sandra Voelker, Kathrin Du...   249.22     4   \n",
      "678   Hanae Ito, Haruka Ueda, Miki Uchida, Yayoi Mat...   217.96     4   \n",
      "2712                             John Frederick Hencken    63.11     1   \n",
      "671   Jasper Aerents, Emmanuel Vanluchene, Pieter Ti...   194.40     4   \n",
      "703   Dominik Kozma, Laszlo Cseh, Peter Bernek, Gerg...   433.66     4   \n",
      "3834                                  Judith Joy Davies    76.70     3   \n",
      "1913                                Kieren John Perkins   225.16     2   \n",
      "4149                               Irmintraut Schneider   314.40     4   \n",
      "\n",
      "      nb_relay    quit_reason  \n",
      "3982       NaN           None  \n",
      "1995       NaN           None  \n",
      "3568       NaN           None  \n",
      "544        NaN           None  \n",
      "2340       NaN           None  \n",
      "1375       NaN           None  \n",
      "299        NaN           None  \n",
      "1012       NaN           None  \n",
      "1785       NaN           None  \n",
      "3975       NaN  Did not start  \n",
      "1028       NaN           None  \n",
      "4275       NaN           None  \n",
      "1395       NaN           None  \n",
      "3080       NaN           None  \n",
      "3573       NaN           None  \n",
      "90         NaN           None  \n",
      "1535       NaN           None  \n",
      "4347       NaN           None  \n",
      "3637       NaN           None  \n",
      "3423       NaN           None  \n",
      "2694       NaN           None  \n",
      "3977       NaN           None  \n",
      "3792       NaN           None  \n",
      "1141       NaN           None  \n",
      "719        NaN           None  \n",
      "566        NaN           None  \n",
      "2354       NaN           None  \n",
      "1239       NaN           None  \n",
      "364        NaN           None  \n",
      "2860       NaN           None  \n",
      "1941       NaN           None  \n",
      "4337       NaN           None  \n",
      "4321       NaN           None  \n",
      "94         NaN           None  \n",
      "3369       NaN           None  \n",
      "3144       NaN           None  \n",
      "1089       NaN           None  \n",
      "2369       NaN           None  \n",
      "813        NaN           None  \n",
      "1125       NaN           None  \n",
      "17         NaN           None  \n",
      "662        NaN           None  \n",
      "1717       4.0           None  \n",
      "678        4.0           None  \n",
      "2712       NaN           None  \n",
      "671        4.0           None  \n",
      "703        4.0           None  \n",
      "3834       NaN           None  \n",
      "1913       NaN           None  \n",
      "4149       4.0           None  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_time_str(time_str):\n",
    "    if isinstance(time_str, str):\n",
    "        # Extraire les chiffres et les séparateurs pertinents\n",
    "        cleaned = re.match(r'^(\\d+:?\\d*:?\\d*\\.?\\d*)', time_str)\n",
    "        if cleaned:\n",
    "            return cleaned.group(1)\n",
    "        elif not re.search(r'\\d', time_str):\n",
    "            return time_str  # Retourner la chaîne si elle ne contient aucun chiffre\n",
    "    return time_str\n",
    "\n",
    "def convert_to_seconds(time_str):\n",
    "    original_value = time_str\n",
    "    time_str = clean_time_str(time_str)\n",
    "    \n",
    "    if isinstance(time_str, float):\n",
    "        return time_str, None  # Déjà en secondes\n",
    "    elif isinstance(time_str, str):\n",
    "        if ':' in time_str:\n",
    "            # Format 00:04:37.510000\n",
    "            time_parts = time_str.split(':')\n",
    "            if len(time_parts) == 3:\n",
    "                hours, minutes, seconds = time_parts\n",
    "                total_seconds = int(hours) * 3600 + int(minutes) * 60 + float(seconds)\n",
    "            else:\n",
    "                minutes, seconds = time_parts\n",
    "                total_seconds = int(minutes) * 60 + float(seconds)\n",
    "        elif re.match(r'^\\d+(\\.\\d+)?$', time_str):\n",
    "            # Format 59.720\n",
    "            total_seconds = float(time_str)\n",
    "        else:\n",
    "            return np.nan, original_value  # Cas de disqualification ou format invalide\n",
    "    else:\n",
    "        return np.nan, str(original_value)  # Cas où le type n'est pas reconnu\n",
    "    \n",
    "    return round(total_seconds, 3), None  # Arrondir à 3 décimales pour la précision milliseconde\n",
    "\n",
    "# Appliquer la conversion à la colonne 'results'\n",
    "df['results'], df['quit_reason'] = zip(*df['results'].apply(convert_to_seconds))\n",
    "\n",
    "# Afficher les premières lignes pour vérification\n",
    "print(df.head())\n",
    "print(\"\\nColonnes du DataFrame:\", df.columns)\n",
    "\n",
    "# Afficher 50 valeurs aléatoires du DataFrame\n",
    "random_sample = df.sample(n=50, random_state=1)  # random_state pour la reproductibilité\n",
    "print(\"\\n50 valeurs aléatoires du DataFrame :\")\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on va traiter le nom des athlètes.\n",
    "\n",
    "Il y a non seulement des noms nuls (qu'on va renommer \"Unknown\"), mais aussi des noms multiples quand il y a des relais.\n",
    "\n",
    "Dans le dernier cas, on va créer un tuple par athlète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id location  year  distance      stroke  is_relay gender team  \\\n",
      "0   1    Tokyo  2020       100  Backstroke     False    Men  ROC   \n",
      "1   2    Tokyo  2020       100  Backstroke     False    Men  ROC   \n",
      "2   3    Tokyo  2020       100  Backstroke     False    Men  USA   \n",
      "3   4    Tokyo  2020       100  Backstroke     False    Men  ITA   \n",
      "4   5    Tokyo  2020       100  Backstroke     False    Men  CHN   \n",
      "\n",
      "              athlete  results  rank  nb_relay  \n",
      "0        Evgeny Rylov    51.98     1       NaN  \n",
      "1  Kliment Kolesnikov    52.00     2       NaN  \n",
      "2         Ryan Murphy    52.19     3       NaN  \n",
      "3       Thomas Ceccon    52.30     4       NaN  \n",
      "4            Jiayu Xu    52.51     4       NaN  \n"
     ]
    }
   ],
   "source": [
    "df['athlete'] = df['athlete'].fillna(\"Unknown\")\n",
    "\n",
    "relay_rows = []\n",
    "\n",
    "# Itérer sur chaque ligne du DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row['is_relay']:\n",
    "        athletes = row['athlete'].split(',')  # Séparer les noms des athlètes\n",
    "        for athlete in athletes:\n",
    "            relay_rows.append({\n",
    "                'id': len(relay_rows) + 1,  # ID autoincrémenté\n",
    "                'location': row['location'],\n",
    "                'year': row['year'],\n",
    "                'distance': row['distance'],\n",
    "                'stroke': row['stroke'],\n",
    "                'is_relay': row['is_relay'],\n",
    "                'gender': row['gender'],\n",
    "                'team': row['team'],\n",
    "                'athlete': athlete.strip(),  # Enlever les espaces\n",
    "                'results': row['results'],\n",
    "                'rank': row['rank'],\n",
    "                'nb_relay': row['nb_relay']\n",
    "            })\n",
    "    else:\n",
    "        relay_rows.append({\n",
    "            'id': len(relay_rows) + 1,\n",
    "            'location': row['location'],\n",
    "            'year': row['year'],\n",
    "            'distance': row['distance'],\n",
    "            'stroke': row['stroke'],\n",
    "            'is_relay': row['is_relay'],\n",
    "            'gender': row['gender'],\n",
    "            'team': row['team'],\n",
    "            'athlete': row['athlete'],\n",
    "            'results': row['results'],\n",
    "            'rank': row['rank'],\n",
    "            'nb_relay': row['nb_relay']\n",
    "        })\n",
    "\n",
    "# Créer un nouveau DataFrame à partir des lignes de relais\n",
    "df_relay_expanded = pd.DataFrame(relay_rows)\n",
    "\n",
    "print(df_relay_expanded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour clarifier le dataframe, voici les différentes colonnes:\n",
    "\n",
    "- location : ville où a eu lieu le tournoi\n",
    "\n",
    "- year : année du tournoi\n",
    "\n",
    "- is_relay : si c'est un relais ou non\n",
    "\n",
    "- distance : distance en mètres de la course (soit la course entière si ce n'est pas un relais, soit la distance de nage pour chaque athlète dans le cas d'un relais)\n",
    "\n",
    "- nb_relay : nombre de relais (None si ce n'est pas un relais)\n",
    "\n",
    "- stroke : type de nage\n",
    "\n",
    "- gender : genre\n",
    "\n",
    "- team : équipe\n",
    "\n",
    "- athlete : nom de l'athlète (Unknown si inconnu)\n",
    "\n",
    "- results : temps réalisé en secondes (float), avec une précision de la microseconde, None si disqualifié\n",
    "\n",
    "- quit_reason : raison de la disqualification (None si pas de disqualification)\n",
    "\n",
    "- rank : classement (0 si disqualifié, 1 si or, 2 si argent, 3 si bronze, 4 si pas de médaille, 5 si pas de donnée)\n",
    "\n",
    "- id : on s'en sert pour former les équipes quand c'est un relais, on ne l'utilise que pour l'ingestion des données en base de données c'est pas important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingérer les données en base de données\n",
    "\n",
    "On commence par connecter la base de données, les variables d'environnement sont stockées dans un fichier .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"DB_USERNAME\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "port = os.getenv(\"DB_PORT\")\n",
    "dbname = os.getenv(\"DB_NAME\")\n",
    "# Création de la base de données\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{dbname}')  # Remplacez par votre URI de base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va découper les données en cinq objets:\n",
    "- Athlete : id (primary key), name, gender\n",
    "- Event : id (primary key), location, year, distance, stroke, is_relay, nb_relay\n",
    "- NationalTeam : id (primary key), code\n",
    "- EventTeam : id (primary key), event_id (foreign key), athlete_id (foreign key), national_team_id (foreign key)\n",
    "- Result : id (primary key), team_id (foreign key), results, rank, quit_reason\n",
    "\n",
    "Ainsi, on normalise les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18580/3533957813.py:6: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Boolean, ForeignKey, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Athlete(Base):\n",
    "    __tablename__ = 'athletes'\n",
    "    \n",
    "    athlete_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String)\n",
    "    gender = Column(String)\n",
    "\n",
    "class Event(Base):\n",
    "    __tablename__ = 'events'\n",
    "    \n",
    "    event_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    location = Column(String)\n",
    "    year = Column(Integer)\n",
    "    distance = Column(Integer)\n",
    "    stroke = Column(String)\n",
    "    is_relay = Column(Boolean)\n",
    "    nb_relay = Column(Integer, nullable=True)\n",
    "\n",
    "class NationalTeam(Base):\n",
    "    __tablename__ = 'national_teams'\n",
    "    \n",
    "    national_team_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    code = Column(String)\n",
    "\n",
    "class EventTeam(Base):\n",
    "    __tablename__ = 'event_teams'\n",
    "    \n",
    "    event_team_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    event_id = Column(Integer, ForeignKey('events.event_id'))\n",
    "    athlete_id = Column(Integer, ForeignKey('athletes.athlete_id'))\n",
    "    national_team_id = Column(Integer, ForeignKey('national_teams.national_team_id'))\n",
    "\n",
    "class Result(Base):\n",
    "    __tablename__ = 'results'\n",
    "    \n",
    "    result_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    event_team_id = Column(Integer, ForeignKey('event_teams.event_team_id'))\n",
    "    results = Column(Float, nullable=True)\n",
    "    rank = Column(Integer)\n",
    "    quit_reason = Column(String, nullable=True)\n",
    "\n",
    "# Création des tables si elles n'existent pas déjà\n",
    "try:\n",
    "    Base.metadata.create_all(engine)\n",
    "except IntegrityError:\n",
    "    print(\"Les tables existent déjà.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin on peuple les tables avec les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de données peuplée avec succès!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "\n",
    "# Création d'une session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Fonctions pour ajouter ou récupérer des données\n",
    "def get_or_create_athlete(name, gender):\n",
    "    athlete = session.query(Athlete).filter_by(name=name, gender=gender).first()\n",
    "    if not athlete:\n",
    "        athlete = Athlete(name=name, gender=gender)\n",
    "        session.add(athlete)\n",
    "        session.commit()\n",
    "    return athlete\n",
    "\n",
    "def get_or_create_event(location, year, distance, stroke, is_relay, nb_relay):\n",
    "    nb_relay = None if is_relay == False else int(nb_relay)\n",
    "    event = session.query(Event).filter_by(location=location, year=year, distance=distance, stroke=stroke, is_relay=is_relay, nb_relay=nb_relay).first()\n",
    "    if not event:\n",
    "        event = Event(location=location, year=year, distance=distance, stroke=stroke, is_relay=is_relay, nb_relay=nb_relay)\n",
    "        session.add(event)\n",
    "        session.commit()\n",
    "    return event\n",
    "\n",
    "def get_or_create_national_team(code):\n",
    "    team = session.query(NationalTeam).filter_by(code=code).first()\n",
    "    if not team:\n",
    "        team = NationalTeam(code=code)\n",
    "        session.add(team)\n",
    "        session.commit()\n",
    "    return team\n",
    "\n",
    "def get_or_create_team(event_id, athlete_id, national_team_id):\n",
    "    team = session.query(EventTeam).filter_by(event_id=event_id, athlete_id=athlete_id, national_team_id=national_team_id).first()\n",
    "    if not team:\n",
    "        team = EventTeam(event_id=event_id, athlete_id=athlete_id, national_team_id=national_team_id)\n",
    "        session.add(team)\n",
    "        session.commit()\n",
    "    return team\n",
    "\n",
    "def get_or_create_result(event_team_id, results, rank, quit_reason):\n",
    "    result = session.query(Result).filter_by(event_team_id=event_team_id, results=results, rank=rank).first()\n",
    "    if not result:\n",
    "        result = Result(event_team_id=event_team_id, results=results, rank=rank, quit_reason=quit_reason)\n",
    "        session.add(result)\n",
    "    return result\n",
    "\n",
    "# Parcourir le dataframe et ajouter les données\n",
    "for _, row in df_relay_expanded.iterrows():\n",
    "    athlete = get_or_create_athlete(row['athlete'], row['gender'])\n",
    "    national_team = get_or_create_national_team(row['team'])\n",
    "    event = get_or_create_event(row['location'], row['year'], row['distance'], row['stroke'], row['is_relay'], row['nb_relay'])\n",
    "    event_team = get_or_create_team(event.event_id, athlete.athlete_id, national_team.national_team_id)\n",
    "    get_or_create_result(event_team.event_team_id, row['results'], row['rank'], row.get('quit_reason'))\n",
    "\n",
    "# Commit final pour sauvegarder toutes les modifications\n",
    "session.commit()\n",
    "\n",
    "# Fermer la session\n",
    "session.close()\n",
    "\n",
    "print(\"Base de données peuplée avec succès!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
