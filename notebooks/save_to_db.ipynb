{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingestion des données en base de données\n",
    "\n",
    "Pour résumer, l'objectif du projet est de s'entraîner en SQL et en Python pour se maintenir à jour en SQL (notamment les CTEs, les windows functions et les RANKS) et en Python (dataframes, SQLAlchemy, Pydantic, FastAPI, tests unitaires, Mock si pertinent, et si pertinent un peu d'intégration de modèles de machine learning).\n",
    "\n",
    "La première chose dans ce notebook ça va être de préparer les données et de les importer dans une DB PostgreSQL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer les données\n",
    "\n",
    "D'abord on regarde les données pour comprendre la structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = \"Olympic_Swimming_Results_1912to2020\"\n",
    "\n",
    "# Lire le fichier CSV et afficher les colonnes\n",
    "df = pd.read_csv(dataset_path + \".csv\")\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "\n",
    "distinct_distances = df['Distance (in meters)'].unique()  # Assurez-vous que le nom de la colonne est correct\n",
    "print(\"Distances distinctes:\", distinct_distances)\n",
    "\n",
    "distinct_results = df['Results'].unique()\n",
    "print(\"Nombre de résultats distincts:\", len(distinct_results))\n",
    "\n",
    "# Sélectionner aléatoirement 100 résultats distincts (ou moins s'il y en a moins de 100)\n",
    "sample_size = min(100, len(distinct_results))\n",
    "random_sample = np.random.choice(distinct_results, size=sample_size, replace=False)\n",
    "\n",
    "print(f\"\\n{sample_size} résultats distincts aléatoires:\")\n",
    "for result in random_sample:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On renomme les colonnes pour les rendre plus faciles à utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Renommer les colonnes\n",
    "df = df.rename(columns={\n",
    "    'Location': 'location',\n",
    "    'Year': 'year',\n",
    "    'Distance (in meters)': 'distance',\n",
    "    'Stroke': 'stroke',\n",
    "    'Relay?': 'is_relay',\n",
    "    'Gender': 'gender',\n",
    "    'Team': 'team',\n",
    "    'Athlete': 'athlete',\n",
    "    'Results': 'results',\n",
    "    'Rank': 'rank'\n",
    "})\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On convertit la colonne is_relay en booléen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'is_relay' en booléen\n",
    "df['is_relay'] = df['is_relay'].map(lambda x: True if x == 1 else False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait la distance et le nombre de relais. On aura besoin de la distance en entier pour analyser correctement les données. Dans le CSV de base c'est un string au format [0-9]+m si c'est pas du relais (e.g 100m), et [0-9]+x[0-9]+m si c'est un relais (e.g 4x100m)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Fonction pour extraire la distance et le nombre de relais\n",
    "def extract_distance_and_relay(distance_str):\n",
    "    if 'x' in distance_str:\n",
    "        nb_relay_str, distance_str = re.findall(r'\\d+', distance_str)\n",
    "        return int(distance_str), int(nb_relay_str)\n",
    "    else:\n",
    "        distance = int(re.findall(r'\\d+', distance_str)[0])\n",
    "        return distance, None\n",
    "\n",
    "# Appliquer la transformation à la colonne 'distance'\n",
    "df['distance'], df['nb_relay'] = zip(*df['distance'].apply(extract_distance_and_relay))\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df_relay_true = df[df['is_relay'] == True]\n",
    "print(df_relay_true.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, faut harmoniser les formats de temps. Dans le CSV de base, les temps sont dans des formats divers, parfois avec des minutes et des secondes, parfois avec des heures, parfois avec des décimales. On va tout convertir en secondes, sous forme de float avec une précision à la microseconde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_time_str(time_str):\n",
    "    if isinstance(time_str, str):\n",
    "        # Extraire les chiffres et les séparateurs pertinents\n",
    "        cleaned = re.match(r'^(\\d+:?\\d*:?\\d*\\.?\\d*)', time_str)\n",
    "        if cleaned:\n",
    "            return cleaned.group(1)\n",
    "        elif not re.search(r'\\d', time_str):\n",
    "            return time_str  # Retourner la chaîne si elle ne contient aucun chiffre\n",
    "    return time_str\n",
    "\n",
    "def convert_to_seconds(time_str):\n",
    "    original_value = time_str\n",
    "    time_str = clean_time_str(time_str)\n",
    "    \n",
    "    if isinstance(time_str, float):\n",
    "        return time_str, None  # Déjà en secondes\n",
    "    elif isinstance(time_str, str):\n",
    "        if ':' in time_str:\n",
    "            # Format 00:04:37.510000\n",
    "            time_parts = time_str.split(':')\n",
    "            if len(time_parts) == 3:\n",
    "                hours, minutes, seconds = time_parts\n",
    "                total_seconds = int(hours) * 3600 + int(minutes) * 60 + float(seconds)\n",
    "            else:\n",
    "                minutes, seconds = time_parts\n",
    "                total_seconds = int(minutes) * 60 + float(seconds)\n",
    "        elif re.match(r'^\\d+(\\.\\d+)?$', time_str):\n",
    "            # Format 59.720\n",
    "            total_seconds = float(time_str)\n",
    "        else:\n",
    "            return np.nan, original_value  # Cas de disqualification ou format invalide\n",
    "    else:\n",
    "        return np.nan, str(original_value)  # Cas où le type n'est pas reconnu\n",
    "    \n",
    "    return round(total_seconds, 3), None  # Arrondir à 3 décimales pour la précision milliseconde\n",
    "\n",
    "# Appliquer la conversion à la colonne 'results'\n",
    "df['results'], df['quit_reason'] = zip(*df['results'].apply(convert_to_seconds))\n",
    "\n",
    "# Afficher les premières lignes pour vérification\n",
    "print(df.head())\n",
    "print(\"\\nColonnes du DataFrame:\", df.columns)\n",
    "\n",
    "# Afficher 50 valeurs aléatoires du DataFrame\n",
    "random_sample = df.sample(n=50, random_state=1)  # random_state pour la reproductibilité\n",
    "print(\"\\n50 valeurs aléatoires du DataFrame :\")\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on va traiter le nom des athlètes.\n",
    "\n",
    "Il y a non seulement des noms nuls (qu'on va renommer \"Unknown\"), mais aussi des noms multiples quand il y a des relais.\n",
    "\n",
    "Dans le dernier cas, on va créer un tuple par athlète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['athlete'] = df['athlete'].fillna(\"Unknown\")\n",
    "\n",
    "relay_rows = []\n",
    "\n",
    "# Itérer sur chaque ligne du DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row['is_relay']:\n",
    "        athletes = row['athlete'].split(',')  # Séparer les noms des athlètes\n",
    "        for athlete in athletes:\n",
    "            relay_rows.append({\n",
    "                'id': len(relay_rows) + 1,  # ID autoincrémenté\n",
    "                'location': row['location'],\n",
    "                'year': row['year'],\n",
    "                'distance': row['distance'],\n",
    "                'stroke': row['stroke'],\n",
    "                'is_relay': row['is_relay'],\n",
    "                'gender': row['gender'],\n",
    "                'team': row['team'],\n",
    "                'athlete': athlete.strip(),  # Enlever les espaces\n",
    "                'results': row['results'],\n",
    "                'rank': row['rank'],\n",
    "                'nb_relay': row['nb_relay']\n",
    "            })\n",
    "    else:\n",
    "        relay_rows.append({\n",
    "            'id': len(relay_rows) + 1,\n",
    "            'location': row['location'],\n",
    "            'year': row['year'],\n",
    "            'distance': row['distance'],\n",
    "            'stroke': row['stroke'],\n",
    "            'is_relay': row['is_relay'],\n",
    "            'gender': row['gender'],\n",
    "            'team': row['team'],\n",
    "            'athlete': row['athlete'],\n",
    "            'results': row['results'],\n",
    "            'rank': row['rank'],\n",
    "            'nb_relay': row['nb_relay']\n",
    "        })\n",
    "\n",
    "# Créer un nouveau DataFrame à partir des lignes de relais\n",
    "df_relay_expanded = pd.DataFrame(relay_rows)\n",
    "\n",
    "print(df_relay_expanded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour clarifier le dataframe, voici les différentes colonnes:\n",
    "\n",
    "- location : ville où a eu lieu le tournoi\n",
    "\n",
    "- year : année du tournoi\n",
    "\n",
    "- is_relay : si c'est un relais ou non\n",
    "\n",
    "- distance : distance en mètres de la course (soit la course entière si ce n'est pas un relais, soit la distance de nage pour chaque athlète dans le cas d'un relais)\n",
    "\n",
    "- nb_relay : nombre de relais (None si ce n'est pas un relais)\n",
    "\n",
    "- stroke : type de nage\n",
    "\n",
    "- gender : genre\n",
    "\n",
    "- team : équipe\n",
    "\n",
    "- athlete : nom de l'athlète (Unknown si inconnu)\n",
    "\n",
    "- results : temps réalisé en secondes (float), avec une précision de la microseconde, None si disqualifié\n",
    "\n",
    "- quit_reason : raison de la disqualification (None si pas de disqualification)\n",
    "\n",
    "- rank : classement (0 si disqualifié, 1 si or, 2 si argent, 3 si bronze, 4 si pas de médaille, 5 si pas de donnée)\n",
    "\n",
    "- id : on s'en sert pour former les équipes quand c'est un relais, on ne l'utilise que pour l'ingestion des données en base de données c'est pas important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingérer les données en base de données\n",
    "\n",
    "On commence par connecter la base de données, les variables d'environnement sont stockées dans un fichier .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"DB_USERNAME\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "port = os.getenv(\"DB_PORT\")\n",
    "dbname = os.getenv(\"DB_NAME\")\n",
    "# Création de la base de données\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{dbname}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va découper les données en cinq objets:\n",
    "- Athlete : id (primary key), name, gender\n",
    "- Event : id (primary key), location, year, distance, stroke, is_relay, nb_relay\n",
    "- NationalTeam : id (primary key), code\n",
    "- EventTeam : id (primary key), event_id (foreign key), athlete_id (foreign key), national_team_id (foreign key)\n",
    "- Result : id (primary key), team_id (foreign key), results, rank, quit_reason\n",
    "\n",
    "Ainsi, on normalise les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Boolean, ForeignKey, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Athlete(Base):\n",
    "    __tablename__ = 'athletes'\n",
    "    \n",
    "    athlete_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String)\n",
    "    gender = Column(String)\n",
    "\n",
    "class Event(Base):\n",
    "    __tablename__ = 'events'\n",
    "    \n",
    "    event_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    location = Column(String)\n",
    "    year = Column(Integer)\n",
    "    distance = Column(Integer)\n",
    "    stroke = Column(String)\n",
    "    is_relay = Column(Boolean)\n",
    "    nb_relay = Column(Integer, nullable=True)\n",
    "\n",
    "class NationalTeam(Base):\n",
    "    __tablename__ = 'national_teams'\n",
    "    \n",
    "    national_team_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    code = Column(String)\n",
    "\n",
    "class EventTeam(Base):\n",
    "    __tablename__ = 'event_teams'\n",
    "    \n",
    "    event_team_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    event_id = Column(Integer, ForeignKey('events.event_id'))\n",
    "    athlete_id = Column(Integer, ForeignKey('athletes.athlete_id'))\n",
    "    national_team_id = Column(Integer, ForeignKey('national_teams.national_team_id'))\n",
    "\n",
    "class Result(Base):\n",
    "    __tablename__ = 'results'\n",
    "    \n",
    "    result_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    event_team_id = Column(Integer, ForeignKey('event_teams.event_team_id'))\n",
    "    results = Column(Float, nullable=True)\n",
    "    rank = Column(Integer)\n",
    "    quit_reason = Column(String, nullable=True)\n",
    "\n",
    "# Création des tables si elles n'existent pas déjà\n",
    "try:\n",
    "    Base.metadata.create_all(engine)\n",
    "except IntegrityError:\n",
    "    print(\"Les tables existent déjà.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin on peuple les tables avec les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "\n",
    "# Création d'une session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Fonctions pour ajouter ou récupérer des données\n",
    "def get_or_create_athlete(name, gender):\n",
    "    athlete = session.query(Athlete).filter_by(name=name, gender=gender).first()\n",
    "    if not athlete:\n",
    "        athlete = Athlete(name=name, gender=gender)\n",
    "        session.add(athlete)\n",
    "        session.commit()\n",
    "    return athlete\n",
    "\n",
    "def get_or_create_event(location, year, distance, stroke, is_relay, nb_relay):\n",
    "    nb_relay = None if is_relay == False else int(nb_relay)\n",
    "    event = session.query(Event).filter_by(location=location, year=year, distance=distance, stroke=stroke, is_relay=is_relay, nb_relay=nb_relay).first()\n",
    "    if not event:\n",
    "        event = Event(location=location, year=year, distance=distance, stroke=stroke, is_relay=is_relay, nb_relay=nb_relay)\n",
    "        session.add(event)\n",
    "        session.commit()\n",
    "    return event\n",
    "\n",
    "def get_or_create_national_team(code):\n",
    "    team = session.query(NationalTeam).filter_by(code=code).first()\n",
    "    if not team:\n",
    "        team = NationalTeam(code=code)\n",
    "        session.add(team)\n",
    "        session.commit()\n",
    "    return team\n",
    "\n",
    "def get_or_create_team(event_id, athlete_id, national_team_id):\n",
    "    team = session.query(EventTeam).filter_by(event_id=event_id, athlete_id=athlete_id, national_team_id=national_team_id).first()\n",
    "    if not team:\n",
    "        team = EventTeam(event_id=event_id, athlete_id=athlete_id, national_team_id=national_team_id)\n",
    "        session.add(team)\n",
    "        session.commit()\n",
    "    return team\n",
    "\n",
    "def get_or_create_result(event_team_id, results, rank, quit_reason):\n",
    "    result = session.query(Result).filter_by(event_team_id=event_team_id, results=results, rank=rank).first()\n",
    "    if not result:\n",
    "        result = Result(event_team_id=event_team_id, results=results, rank=rank, quit_reason=quit_reason)\n",
    "        session.add(result)\n",
    "    return result\n",
    "\n",
    "# Parcourir le dataframe et ajouter les données\n",
    "for _, row in df_relay_expanded.iterrows():\n",
    "    athlete = get_or_create_athlete(row['athlete'], row['gender'])\n",
    "    national_team = get_or_create_national_team(row['team'])\n",
    "    event = get_or_create_event(row['location'], row['year'], row['distance'], row['stroke'], row['is_relay'], row['nb_relay'])\n",
    "    event_team = get_or_create_team(event.event_id, athlete.athlete_id, national_team.national_team_id)\n",
    "    get_or_create_result(event_team.event_team_id, row['results'], row['rank'], row.get('quit_reason'))\n",
    "\n",
    "# Commit final pour sauvegarder toutes les modifications\n",
    "session.commit()\n",
    "\n",
    "# Fermer la session\n",
    "session.close()\n",
    "\n",
    "print(\"Base de données peuplée avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vais juste convertir les NULL dans nb_relay en 1, je vais pas refactoriser, juste en executant la cell ça remplacera les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les valeurs NULL de nb_relay par 1 dans la table events\n",
    "from sqlalchemy import update\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "stmt = update(Event).where(Event.nb_relay.is_(None)).values(nb_relay=1)\n",
    "session.execute(stmt)\n",
    "session.commit()\n",
    "\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
